# Foregående spørgsmål

# Introduktioner
- Johannes Kruse: Arbejder på LUKE; mere eksplorativ på LUKE og ser på fortolkbarhed samt visualisering af transformermodeller 
- Martin: En fjerdedel af Danspeech sammen med Rasmus. Startede på speciale med open-source dansk talegenkendelse. Fokuseret på kommercialisering og anvendelse i virkeligheden. NER er interessant for talegenkendelse (tekstuel post-processering). Kunderne vil gerne kende have kontekst ind i post-processering.
- Michael Riis Andersen: Underviser i bayesianske kurser + interesseret i NLP, hvor han arbejder i børneskrive-projekt, hvor NER er relevant. Men mange eksisterende værktøjer virker ikke på lowercase-tekst.
- Rasmus Arpe: I høj grad samme historie som Martin - arbejder på talegenkendelsen og de efterfølgende lag.

- Lars Kai har ikke tiltro til Digitaliseringsstyrelsens projekt - der skal hjælp på vej
- Bernd og Lars Kai har været godt igang med kommunikation og det kan vist ikke lade sig gøre at fjerne 24-timers grænsen, men det kan deles op i bestanddele af 24 timer.
- Undersøg fejltyper
- LUKE har integreret entitetsmasken
- LK forestiller sig, at man skal starte med et minimalprodukt med dansk BERT og forholdsvist begrænset datasæt
- JK taler om Lukas + vil gerne mødes
- Martin: Se på Stanford-modellers motivation for klasser
- LK: Se på output-fordelinger af output
- Rasmus og Martin har noget ikke-open source DR og Alt for Damerne. LK forestiller sig, at man kunne maskinelt annotere teksten. DR var særligt interessant, da der er mange entiteter
- Rasmus: Det kan give mening at lave en vidensgraf ud fra nogle tekster.
- Finn talte om et NST-datasæt


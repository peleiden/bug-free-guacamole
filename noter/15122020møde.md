# Spørgsmål inden mødet
- Hvad er vores rolle i udviklingen af dansk LUKE: Skal det være produktet i vores bachelor?
- Hvor stor en rolle spiller NER i dette: er NER målet for os eller bruger vi bare Wikipedia-NE som en del af træningen?
- I LUKE testes modellen på CoNLL-2003-NER-datasættet. Det er jo ikke på dansk. Skal vi bruge DaNE eller DKIE i stedet? Kan man bare sådan teste på et andet datasæt?
- Hvor meget er der fokus på type og hvor meget er der forskel på NE-genkendelse? Hvordan får man overhovedet (CoNLL-agtige typer fra Wikipedia)?

# 
- Johannes Kruse: Igang med speciale vejledt af LK. Fokuserer på LUKE. Bruger tid på NLP og har arbejdet med infosys med NLP.
- Victor Elkjær Birk: Færdig med kandidat i februar. Er konsulent i IBM, hvor han også arbejder en del med IBM. Baggrund: Fysik. 
- Michael Riis Andersen: Adjunkt 
- Fin Årup startede i høj grad NLP hos CogSys
- Der er mange grupper: ITU, Århus, Alexandra-institutet.
- Lars foreslår projektplan: 2 punkter er reproduktion og burde gå hurtigt.
- Det tredje punkt er langt sværere: Dansk LUKE.
- LUKE gør tingene anderledes: NoBERT har vidensgrafen eksplicit, men LUKE træner det grundlæggende.
- LUKE træner repræsentationer af NE'er fra bunden af 
- Multi-GPU: Sebastian fra Compute-centeret + danspeech-projektet med Martin og Rasmus.
- Finn har lavet en ressource, han har trukket ud af Wikidata Finn's name list.
- Tekstforslag: Folketinget.
- DTU er med i en stor europæisk opgradering af compute.
Lars Kai: 
Suggested project plan: 1) Reproduce Danish NER benchmarks Inspiration here: https://github.com/alexandrainst/danlp/blob/master/docs/docs/tasks/ner.md Finn's name list, Wikidata+Dannet 2) Reproduce English LUKE NER based on Johannes and Victor results 3) Train Danish LUKE for NER on benchmark data 4) Produce Danish open source LUKE with NER as example and comparison with existing NER benchmarks



